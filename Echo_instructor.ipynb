{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import string\n",
    "import math \n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input to modify\n",
    "- Path to parameter file in tsv, make sure the format/column names are exactly the same as example: 'tests\\data\\sampler\\input\\parameters.tsv'. Column names are: Component, maxValue, stockConcentration, deadVolume, Ratios\n",
    "- out_path: folder for ALL files (from sampler to instructor), please generate new folder for different samples, otherwise modification will be made with unnecessary files. It's possible to have different folders for convert,plates generate... however you have change file names manually at each step\n",
    "- nb_sample: number of sample generated from parameter files using latin hypercube\n",
    "- Volume_file: .tsv of experiments in volume.\n",
    "- nb_replicate: number of replications\n",
    "- volume_path: path and file name to save replicated samples\n",
    "- min_volume/max_volume: machine transfer volumn limit, outside of this range the machine transfer volumn cannot guaranty to be correct, usually within [20; 1000] nL, Mahnaz has already tested up to 2000nL\n",
    "- source_size: size of source plate\n",
    "- inexpensive_component: list of component that can split into multiple well in source plates tp speed up transfer\n",
    "- max_volume_source: the max value can fill in source plate\n",
    "- optimal_volume_source: some volumn smaller than the max above, this is the level that inexpensive can be fill \n",
    "- dead_volumn of source wells\n",
    "- extra: number < 1, represent the extra percentage of source concentration in source plate, use to calculate the final filling volumes\n",
    "- to_split_component: list of name of components, where they need to be fill first or later than other components, therefore, theirs instructor will be seperated to feed first/later to ECHO\n",
    "- viscous_component: change Source Plate Type into '384PP_AQ_CP' , instead of default '384PP_AQ_GP3'\n",
    "\n",
    "NOTICE: all path or string should be within \"\" instead of ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_path = \"al_test\\\\240202_param.txt\"\n",
    "out_path = \"round3\"\n",
    "\n",
    "# generated sample \n",
    "nb_sample = 100\n",
    "\n",
    "# volume\n",
    "volumn_file = \"/sampling_volumes.tsv\"\n",
    "volume_path = out_path + \"/sampling_volumes.tsv\"\n",
    "nb_replicate = 6\n",
    "shuffle = False\n",
    "\n",
    "# machine transfer limit\n",
    "min_volume = 20\n",
    "max_volume = 1000\n",
    "\n",
    "# source plate\n",
    "source_size = [16,24]\n",
    "inexpensive_component = [\"Water\"]\n",
    "max_volume_source = 60000\n",
    "optimal_volume_source = 30000\n",
    "dead_volumn = 15000\n",
    "extra = 0.5\n",
    "\n",
    "\n",
    "# instrutor \n",
    "to_split_component = [\"HEPES\",\"Malachite green\"]\n",
    "viscous_component = ['PEG-8000']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions needed, no modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_values(value, lower_limit, upper_limit, nb_column):\n",
    "    int_divide = int(value // upper_limit)\n",
    "    residual = value % upper_limit\n",
    "\n",
    "    if (residual < lower_limit) & (int_divide > 0):\n",
    "        full_column = int_divide - 1\n",
    "    else:\n",
    "        full_column = int_divide\n",
    "    \n",
    "    result = [upper_limit]*full_column\n",
    "    result += [value - full_column*upper_limit]\n",
    "    result += [0]*(nb_column-full_column-1)\n",
    "    return result\n",
    "\n",
    "def find_well(source_size, first_well, size):\n",
    "    names_list = []\n",
    "\n",
    "    # Get the first letters of the alphabet\n",
    "    alphabet_letters = string.ascii_uppercase[:source_size[0]]\n",
    "\n",
    "    # Generate combinations\n",
    "    for number in range(1, source_size[1]):\n",
    "        for letter in alphabet_letters:\n",
    "            name = letter + str(number)\n",
    "            names_list.append(name)\n",
    "    \n",
    "    #find where is the first index in name list\n",
    "    start_idx = names_list.index(first_well)\n",
    "    well_list = names_list[start_idx:(start_idx+size)]\n",
    "\n",
    "    return well_list\n",
    "\n",
    "def divide_volumn(dead_volumn, limit_volume, vol):\n",
    "    capacity = limit_volume - dead_volumn\n",
    "    nb_well = math.ceil(vol/capacity)\n",
    "    result = [min(limit_volume, round((vol - i*capacity + dead_volumn),-2)) for i in range(nb_well)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample new experiments from latin hypercube\n",
    "Skip if using result from active learning\n",
    "- Input: Path to a .tsv file containing cfps parameters and features, optional: nb of samples and output folder\n",
    "- Output: sampling.tsv\n",
    "More info, please run these command in a seperated cell \n",
    "\n",
    "\n",
    "%%cmd \n",
    "python -m icfree.sampler --help\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mList of parameters\u001b[0m\n",
      "\u001b[32m   Mg-glutamate\t(6 possible values)\u001b[0m\n",
      "\u001b[32m   K-glutamate\t(6 possible values)\u001b[0m\n",
      "\u001b[32m   Amino acid\t(6 possible values)\u001b[0m\n",
      "\u001b[32m   Spermidine\t(6 possible values)\u001b[0m\n",
      "\u001b[32m   3-PGA\t(6 possible values)\u001b[0m\n",
      "\u001b[32m   NTPs\t(6 possible values)\u001b[0m\n",
      "\u001b[32m   PEG-8000\t(6 possible values)\u001b[0m\n",
      "\u001b[32m   DNA\t(6 possible values)\u001b[0m\n",
      "\u001b[32m   HEPES\t(1 possible values)\u001b[0m\n",
      "\u001b[32m   Malachite green\t(1 possible values)\u001b[0m\n",
      "\u001b[32m\u001b[0m\n",
      "\u001b[32mMaximum number of unique samples: 1679616\u001b[0m\n",
      "\u001b[32m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icfree.sampler 2.1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run -m icfree.sampler {parameter_path} --nb-samples $nb_sample -of $out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert from concentration into volume of source mediums\n",
    "\n",
    "- Input: Path to a .tsv parameter file and files, .tsv sampling (or active learning files), optional: -v (destination maximun volume, here 10.5 µL) and -of (output folder)\n",
    "- Output: sampling_volumes.tsv\n",
    "More info, please run these command in a seperated cell \n",
    "\n",
    "\n",
    "%%cmd \n",
    "python -m icfree.converter --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [version 10.0.19045.3930]\n",
      "(c) Microsoft Corporation. Tous droits r�serv�s.\n",
      "\n",
      "(cellfree) c:\\Users\\tnhoang\\Documents\\icfree\\icfree-ml>python -m icfree.converter \"al_test\\240202_param.txt\" \"round3\\round4_ei.csv\" -v 10500 -of round3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mConverting concentrations to volumes...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(cellfree) c:\\Users\\tnhoang\\Documents\\icfree\\icfree-ml>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "python -m icfree.converter \"al_test\\240202_param.txt\" \"round3\\round4_ei.csv\" -v 10500 -of round3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some modifications:\n",
    "- If add control, should add in volumn before this step\n",
    "- Calculated balance volume for next step, aka the level of all wells, reached by add different water level to different well. This result (here 812nL) will be input for plate_generator command\n",
    "- Multiple volume file n times, for repetitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well_volume 5970 nL\n"
     ]
    }
   ],
   "source": [
    "volumn = pd.read_csv(out_path + volumn_file, sep='\\t')\n",
    "accumulate_volumn = np.sum(volumn, axis = 1)\n",
    "max_plate = np.max(accumulate_volumn)\n",
    "print(f'Well_volume {math.ceil(max_plate + min_volume)} nL')\n",
    "\n",
    "# repeat samples\n",
    "volumn = pd.concat([volumn]*nb_replicate, ignore_index=True)\n",
    "if shuffle:\n",
    "    volumn = volumn.sample(frac=1)\n",
    "volumn.to_csv(volume_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated sample position on destination plates and the water amount to add\n",
    "\n",
    "- Input: Path to a .tsv parameter file and files .tsv sampling IN VOLUMN\n",
    "- Optional: -v (number calculated above, here 812 µL), -of (output folder), -dsw (beginning well position for DESTINATION plate, here H3), --ssw (beginning well position for SOURCE plate, here B1)\n",
    "- Output: destination_plate (.csv and .json) and source_plate(.csv and .json), also volumn_summary\n",
    "More info, please run these command in a seperated cell \n",
    "\n",
    "\n",
    "%%cmd \n",
    "python -m icfree.plates_generator --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [version 10.0.19045.3930]\n",
      "(c) Microsoft Corporation. Tous droits r�serv�s.\n",
      "\n",
      "(cellfree) c:\\Users\\tnhoang\\Documents\\icfree\\icfree-ml>python -m icfree.plates_generator \"al_test\\240202_param.txt\" \"round3\\sampling_volumes.tsv\" -of round3 -v 5970 -dsw A1 -ssw B1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(cellfree) c:\\Users\\tnhoang\\Documents\\icfree\\icfree-ml>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "python -m icfree.plates_generator \"al_test\\240202_param.txt\" \"round3\\sampling_volumes.tsv\" -of round3 -v 5970 -dsw A1 -ssw B1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some modifications\n",
    "- Modify destination column to fit within transfer volumn of ECHO, if the volume is too big, split column_A into column_A_1, column_A_2...within the limit, unless the residual (or last column) is smaller than lower limit, combine this residual with the previous volume (we prefer value bigger than upper limit, than smaller than lower limit)\n",
    "- At the same time, modify source file .csv with the new column names. Also, re-calculate volume of source plate as total volume need multiple some extra percentages. Some expensive component will be kept in the least well the possible (to avoid waste by dead volumn), other inexpensive components will be fill to an optimal volume only, therefore machine has multiple source to take and can skip some waiting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_list = glob.glob(os.path.join(out_path, 'destination_plate_*.csv'))\n",
    "\n",
    "#import each destination plate\n",
    "for plate in plate_list:\n",
    "    plate_data = pd.read_csv(plate)\n",
    "\n",
    "    #find which component volumn is too big\n",
    "    idx = plate_data.columns[1:]\n",
    "    component_max_vol = np.max(plate_data.iloc[:,1:], axis = 0)\n",
    "    component_list = idx[component_max_vol > max_volume].tolist()\n",
    "\n",
    "    for component in component_list:\n",
    "        # calculate how many column to divide \n",
    "        highest = component_max_vol[component]\n",
    "        res = highest % max_volume\n",
    "        col = int(highest // max_volume)\n",
    "        if  (res > min_volume) | (col == 0):\n",
    "            col += 1\n",
    "\n",
    "        # make new column name \n",
    "        name_list = []\n",
    "        for order in range(col):\n",
    "            name_list += [component + '_' + str(order + 1)]\n",
    "\n",
    "        # Apply the function to create new columns\n",
    "        plate_data[name_list] = pd.DataFrame(plate_data[component].apply(lambda x: split_values(x, min_volume, max_volume, col)).to_list(), index=plate_data.index)\n",
    "\n",
    "        # Drop the original 'value' column if you want\n",
    "        plate_data = plate_data.drop(columns=[component])\n",
    "  \n",
    "\n",
    "    # save the modify files\n",
    "    plate_data.to_csv(plate, index= False)\n",
    "\n",
    "    # open source file for the same destination files\n",
    "    source = plate.replace(\"destination\",\"source\")\n",
    "    source_data = pd.read_csv(source)\n",
    "\n",
    "\n",
    "    # calculate source volumn needed\n",
    "    volumn_need = np.sum(plate_data, axis = 0)[1:]\n",
    "    volumn_need = np.array(volumn_need)*extra\n",
    "    component_name = plate_data.columns[1:]\n",
    "\n",
    "    # re-arrange column with desire volumn\n",
    "    source_frame = pd.DataFrame([])\n",
    "    for i in range(len(component_name)):\n",
    "        name = component_name[i]\n",
    "        vol = volumn_need[i]\n",
    "        # divide columns according to inexpensive or expensive \n",
    "        if any([item in name for item in inexpensive_component]):\n",
    "            result = divide_volumn(dead_volumn, optimal_volume_source, vol)\n",
    "        else: \n",
    "            result = divide_volumn(dead_volumn, max_volume_source, vol)\n",
    "        result = pd.DataFrame(result, columns=[component_name[i]])\n",
    "        source_frame = pd.concat([source_frame,result], axis = 0, join = 'outer')\n",
    "    \n",
    "    # assign well column\n",
    "    first_source_well = source_data.Well[0]\n",
    "    nb__well_source = source_frame.shape[0]\n",
    "    source_well_destination = find_well(source_size, first_source_well, nb__well_source)\n",
    "    source_frame.insert(0, 'Well', source_well_destination)\n",
    "\n",
    "    # save source file\n",
    "    source_frame.to_csv(source, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate from plate composition and destinations into machine instructors\n",
    "\n",
    "- Input: Path to .json source file (or files) and .json destination file (or files)\n",
    "- Optional: -of (output folder), -spt (to change Source_Plate_Type, here use CP instead of GP3)\n",
    "- Output: instructors.csv and volumes_warning.txt (capture all warning)\n",
    "More info, please run these command in a seperated cell \n",
    "\n",
    "\n",
    "%%cmd \n",
    "python -m icfree.instructor --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [version 10.0.19045.3930]\n",
      "(c) Microsoft Corporation. Tous droits r�serv�s.\n",
      "\n",
      "(cellfree) c:\\Users\\tnhoang\\Documents\\icfree\\icfree-ml>python -m icfree.instructor --source_plates \"round3\\source_plate_1.json\" --dest_plates \"round3\\destination_plate_1.json\" -of round3 \n",
      "\n",
      "(cellfree) c:\\Users\\tnhoang\\Documents\\icfree\\icfree-ml>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "python -m icfree.instructor --source_plates \"round3\\source_plate_1.json\" --dest_plates \"round3\\destination_plate_1.json\" -of round3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [version 10.0.19045.3930]\n",
      "(c) Microsoft Corporation. Tous droits r�serv�s.\n",
      "\n",
      "(cellfree) c:\\Users\\tnhoang\\Documents\\icfree\\icfree-ml>python -m icfree.instructor --help\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Generates instructions for robots\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --source_plates SOURCE_PLATES [SOURCE_PLATES ...]\n",
      "                        Path to .json files containing source plates\n",
      "                        information\n",
      "  --source_wells SOURCE_WELLS [SOURCE_WELLS ...]\n",
      "                        Path to .csv/tsv files containing source wells\n",
      "                        content. If set, overwrite \"Wells\" entry in .json\n",
      "                        file.\n",
      "  --dest_plates DEST_PLATES [DEST_PLATES ...]\n",
      "                        Path to .json files containing destination plates\n",
      "                        information\n",
      "  --dest_wells DEST_WELLS [DEST_WELLS ...]\n",
      "                        Path to .csv/tsv files containing dest wells content.\n",
      "                        If set, overwrite \"Wells\" entry in .json file.\n",
      "  --robot ROBOT         Name of the robot to use (default: echo)\n",
      "  -of OUTPUT_FOLDER, --output-folder OUTPUT_FOLDER\n",
      "                        Output folder to write output files (default:\n",
      "                        c:\\Users\\tnhoang\\Documents\\icfree\\icfree-ml)\n",
      "  -spt SRC_PLATE_TYPE [SRC_PLATE_TYPE ...], --src-plate-type SRC_PLATE_TYPE [SRC_PLATE_TYPE ...]\n",
      "                        Source plate type (for ECHO robot). If number of args\n",
      "                        is odd, the first arg is the plate type by default.\n",
      "                        Then, each pair of args is a sample ID and a plate\n",
      "                        type. (default: 384PP_AQ_GP3)\n",
      "  --log ARG, -l ARG     Adds a console logger for the specified level\n",
      "                        (default: error)\n",
      "  --log_file LOG_FILE   Filename where to put logs\n",
      "  --silent, -s          run instructor silently\n",
      "  --version             show the version number and exit\n",
      "\n",
      "(cellfree) c:\\Users\\tnhoang\\Documents\\icfree\\icfree-ml>"
     ]
    }
   ],
   "source": [
    "%%cmd \n",
    "python -m icfree.instructor --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete no volumn instruction and slit instructions if some component needed to be run first/later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_list = glob.glob(os.path.join(out_path, 'instructions*.csv'))\n",
    "\n",
    "for file in instruction_list:\n",
    "    instruction_data = pd.read_csv(file)\n",
    "\n",
    "    # delete transfer has 0 volume\n",
    "    idx = instruction_data['Transfer Volume'] == 0\n",
    "    instruction_data = instruction_data[~idx]\n",
    "\n",
    "    # change Source Plate Type of vicous component into 384PP_AQ_CP\n",
    "    for name in viscous_component:\n",
    "        idx = pd.Series([str(value).startswith(name) for value in instruction_data['Sample ID']], index = instruction_data.index)\n",
    "        idx = idx.reindex(instruction_data.index)\n",
    "        instruction_data.loc[idx, \"Source Plate Type\"] = \"384PP_AQ_CP\"\n",
    "\n",
    "    # split into multiple instruction files depend on component\n",
    "    for name in to_split_component:\n",
    "        if not to_split_component:\n",
    "            print('No component to split')\n",
    "        idx = pd.Series([str(value).startswith(name) for value in instruction_data['Sample ID']], index = instruction_data.index)\n",
    "        idx = idx.reindex(instruction_data.index)\n",
    "        subset_instructor = instruction_data[idx]\n",
    "        instruction_data = instruction_data[~idx]\n",
    "\n",
    "        sub_name = file.replace(\".csv\",\"_\" + name + \".csv\")\n",
    "        subset_instructor.to_csv(sub_name, index = False)\n",
    "        \n",
    "    instruction_data.to_csv(file, index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellfree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
